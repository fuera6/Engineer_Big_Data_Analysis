# 데이터 모형 구축 작업

## 분석 모형 선정
* 지도학습
    * 회귀분석 (regression analysis)
    * 로지스틱 회귀 분석 (logistic regression)
    * 나이브 베이즈 (Naïve Bayes)
    * 최근접이웃 (KNN)
    * 의사결정 나무 (decision tree)
    * 인공신경망 (artificial neural network, ANN)
    * 서포트 벡터 머신 (support vector machine, SVM)
    * 랜덤포레스트 (random forest)
* 비지도학습
    * 군집화 (K-Means, SOM-자기조직화지도, 계층군집 등)
    * 차원축소 (주성분분석, 선형판별분석 등)
    * 연관분석 (association analysis)
    * 인공신경망 (artificial neural network, ANN)

## 하이퍼파라미터 튜닝
하이퍼파라미터 (hyperparameter): 분석 모형이 학습을 통해 파라미터를 찾기 위해서 분석 모형 자체에 설정하는 분석 모형 외부 파라미터
* 하이퍼파라미터 튜닝 방법
    * 매뉴얼 서치 (manual search): 사용자 직감에 의한 서칭, 경험의존적 조정, 비효율적
    * 그리드 서치 (grid search): 가능한 모든 하이퍼파라미터 조합을 시도하여 최적 파라미터를 찾는 방법, 계산 시간이 길다는 단점이 있음
    * 랜덤 서치 (random search): 하이퍼파라미터 값의 범위를 지정하고 무작위 표본 추출로 찾는 방법

## 데이터 분할 방법
* 홀드아웃 (Hold-Out)
    * 가장 보편적인 방법으로 랜덤 추출을 통해 데이터를 분할
    * 일반적으로 train data (+validation data)를 60~80%, test data를 20~40%로 분할
* K-fold 교차검증 (K-fold cross validation)
    * test data를 제외한 데이터를 무작위로 중복되지 않는 K개의 데이터로 분할
    * K-1개의 데이터를 train data로 사용하고 나머지 1개를 validation data로 사용
    * validation data를 바꾸며 K번 반복해 분할된 데이터를 한 번씩 validation data로 사용
* 부트스트랩 검증 (Bootstrap)
    * 데이터의 분포가 치우쳐 있거나 데이터 건수가 너무 적을 때 사용
    * 복원추출을 통해 전체 데이터와 동일한 사이즈의 샘플 데이터를 추출 후, 추출된 샘플 데이터를 train data로 사용하고 한 번도 추출되지 않은 나머지 데이터를 validation data 또는 test data로 사용